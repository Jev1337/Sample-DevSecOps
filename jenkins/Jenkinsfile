pipeline {
    agent any

    environment {
        REGISTRY = 'localhost:32000'
        IMAGE_NAME = 'flask-k8s-app'
        TAG = "build-${env.BUILD_NUMBER}"
        SONAR_HOST_URL = "http://sonarqube.local:9000"
        SONAR_PROJECT_KEY = "flask-k8s-devsecops"
        SONAR_TOKEN = credentials('SONAR_TOKEN')
    }

    stages {
        stage('Checkout') {
            steps {
                checkout scm
            }
        }

        stage('Install Dependencies') {
            steps {
                dir('app') {
                    sh '''
                        python3 -m venv venv
                        . venv/bin/activate
                        python -m pip install --upgrade pip
                        python -m pip install -r requirements.txt
                    '''
                }
            }
        }

        stage('Run Tests') {
            steps {
                dir('app') {
                    sh '''
                        . venv/bin/activate
                        python -m pytest tests/ -v \
                            --cov=. \
                            --cov-report=xml \
                            --cov-report=html \
                            --junitxml=test-results.xml
                    '''
                }
            }
            post {
                always {
                    archiveArtifacts artifacts: 'app/htmlcov/**/*', allowEmptyArchive: true
                    junit 'app/test-results.xml'
                }
            }
        }
        /*
        stage('SonarQube Analysis') {
            steps {
                script {
                    withSonarQubeEnv('SonarQube') {
                        dir('app') {
                            sh '''
                                sonar-scanner \
                                    -Dsonar.projectKey=${SONAR_PROJECT_KEY} \
                                    -Dsonar.sources=. \
                                    -Dsonar.host.url=${SONAR_HOST_URL} \
                                    -Dsonar.login=${SONAR_TOKEN} \
                                    -Dsonar.python.coverage.reportPaths=coverage.xml \
                                    -Dsonar.python.xunit.reportPath=test-results.xml
                            '''
                        }
                    }
                }
            }
        }
        */

        stage('Trivy FS Scan') {
            steps {
                sh "trivy fs --format table -o trivy-fs-report.txt --severity HIGH,CRITICAL ."
                archiveArtifacts artifacts: 'trivy-fs-report.txt', allowEmptyArchive: true
            }
        }

        stage('Build & Push Image') {
            steps {
                script {
                    def fullImageName = "${env.REGISTRY}/${env.IMAGE_NAME}:${env.TAG}"
                    def buildNumber = env.BUILD_NUMBER
                    
                    // Get current git info
                    def gitCommit = sh(script: 'git rev-parse HEAD', returnStdout: true).trim()
                    def gitUrl = sh(script: 'git config --get remote.origin.url', returnStdout: true).trim()
                    
                    sh """
                        # Create and run Kaniko build job using Python Kubernetes API
                        python3 << 'PYEOF'
import time
import yaml
from kubernetes import client, config

# Load in-cluster config
config.load_incluster_config()

# Create API clients
batch_v1 = client.BatchV1Api()
v1 = client.CoreV1Api()

# Job manifest
job_manifest = {
    'apiVersion': 'batch/v1',
    'kind': 'Job',
    'metadata': {
        'name': 'kaniko-build-${buildNumber}',
        'namespace': 'jenkins'
    },
    'spec': {
        'template': {
            'spec': {
                'restartPolicy': 'Never',
                'containers': [{
                    'name': 'kaniko',
                    'image': 'gcr.io/kaniko-project/executor:latest',
                    'args': [
                        '--context=git://${gitUrl}#${gitCommit}',
                        '--context-sub-path=app',
                        '--dockerfile=app/Dockerfile',
                        '--destination=${fullImageName}',
                        '--insecure',
                        '--skip-tls-verify',
                        '--verbosity=info'
                    ]
                }]
            }
        }
    }
}

print("Creating Kaniko build job...")
try:
    # Create the job
    job = batch_v1.create_namespaced_job(namespace='jenkins', body=job_manifest)
    print(f"Job created: {job.metadata.name}")
    
    # Wait for job completion
    print("Waiting for build job to complete...")
    for i in range(24):  # 4 minute timeout (reduced from 10 minutes)
        try:
            job_status = batch_v1.read_namespaced_job(name='kaniko-build-${buildNumber}', namespace='jenkins')
            
            # Show job progress
            active_jobs = job_status.status.active or 0
            failed_jobs = job_status.status.failed or 0
            succeeded_jobs = job_status.status.succeeded or 0
            
            print(f"Job status - Active: {active_jobs}, Failed: {failed_jobs}, Succeeded: {succeeded_jobs}")
            
            # If we have multiple failures, fail fast and show logs
            if failed_jobs >= 2:
                print(f"‚ùå Multiple pod failures detected ({failed_jobs} failures)")
                pods = v1.list_namespaced_pod(namespace='jenkins', label_selector='job-name=kaniko-build-${buildNumber}')
                if pods.items:
                    # Show logs from first failed pod
                    for pod in pods.items:
                        if pod.status.phase == 'Failed':
                            pod_name = pod.metadata.name
                            print(f"FAILURE LOGS from {pod_name}:")
                            try:
                                logs = v1.read_namespaced_pod_log(name=pod_name, namespace='jenkins')
                                print(logs)
                            except Exception as log_error:
                                print(f"Could not get logs: {log_error}")
                            break
                
                # Cleanup and exit
                try:
                    batch_v1.delete_namespaced_job(name='kaniko-build-${buildNumber}', namespace='jenkins')
                except:
                    pass
                exit(1)
            
            # Show pod status too
            pods = v1.list_namespaced_pod(namespace='jenkins', label_selector='job-name=kaniko-build-${buildNumber}')
            if pods.items:
                for pod in pods.items:
                    pod_name = pod.metadata.name
                    pod_phase = pod.status.phase
                    print(f"Pod {pod_name}: {pod_phase}")
                    
                    # If pod failed, show error logs immediately
                    if pod_phase == 'Failed':
                        try:
                            logs = v1.read_namespaced_pod_log(name=pod_name, namespace='jenkins')
                            print(f"ERROR LOGS from {pod_name}:")
                            if logs:
                                print(logs[-1000:])  # Show last 1000 chars
                            else:
                                print("  No logs available")
                        except Exception as log_error:
                            print(f"Could not get error logs: {log_error}")
                    
                    # If pod is running, show recent logs
                    elif pod_phase == 'Running' and i > 1:  # Check logs earlier
                        try:
                            logs = v1.read_namespaced_pod_log(name=pod_name, namespace='jenkins', tail_lines=3)
                            print(f"Recent logs from {pod_name}:")
                            if logs:
                                log_lines = logs.split("\\n")
                                for line in log_lines[-2:]:
                                    if line.strip():
                                        print(f"  {line}")
                        except Exception as log_error:
                            print(f"Could not get logs: {log_error}")
            
            if job_status.status.conditions:
                for condition in job_status.status.conditions:
                    if condition.type == 'Complete' and condition.status == 'True':
                        print("‚úÖ Build completed successfully")
                        
                        # Get and show logs
                        pods = v1.list_namespaced_pod(namespace='jenkins', label_selector='job-name=kaniko-build-${buildNumber}')
                        if pods.items:
                            pod_name = pods.items[0].metadata.name
                            print("Build logs:")
                            try:
                                logs = v1.read_namespaced_pod_log(name=pod_name, namespace='jenkins', tail_lines=10)
                                print(logs)
                            except Exception as log_error:
                                print(f"Could not get logs: {log_error}")
                        
                        # Cleanup job
                        try:
                            batch_v1.delete_namespaced_job(name='kaniko-build-${buildNumber}', namespace='jenkins')
                            print("Job cleaned up")
                        except:
                            pass
                        
                        print("Successfully built and pushed ${fullImageName}")
                        exit(0)
                        
                    elif condition.type == 'Failed' and condition.status == 'True':
                        print("‚ùå Build failed")
                        
                        # Get and show error logs
                        pods = v1.list_namespaced_pod(namespace='jenkins', label_selector='job-name=kaniko-build-${buildNumber}')
                        if pods.items:
                            pod_name = pods.items[0].metadata.name
                            print("Error logs:")
                            try:
                                logs = v1.read_namespaced_pod_log(name=pod_name, namespace='jenkins')
                                print(logs)
                            except Exception as log_error:
                                print(f"Could not get logs: {log_error}")
                        
                        # Cleanup job
                        try:
                            batch_v1.delete_namespaced_job(name='kaniko-build-${buildNumber}', namespace='jenkins')
                        except:
                            pass
                        
                        exit(1)
            
            print(f"Waiting for job completion... (attempt {i+1}/24)")
            time.sleep(10)
            
        except Exception as e:
            print(f"Error checking job status: {e}")
            time.sleep(5)  # Shorter sleep on error
    
    print("Job timed out after 4 minutes")
    # Cleanup on timeout
    try:
        batch_v1.delete_namespaced_job(name='kaniko-build-${buildNumber}', namespace='jenkins')
    except:
        pass
    exit(1)
    
except Exception as e:
    print(f"Failed to create build job: {e}")
    exit(1)

PYEOF
                    """
                }
            }
        }

        stage('Trivy Image Scan') {
            steps {
                script {
                    def fullImageName = "${env.REGISTRY}/${env.IMAGE_NAME}:${env.TAG}"
                    sh "trivy image --format table -o trivy-image-report.txt --severity HIGH,CRITICAL ${fullImageName} || true"
                }
                archiveArtifacts artifacts: 'trivy-image-report.txt', allowEmptyArchive: true
            }
        }

        stage('Deploy to Kubernetes') {
            steps {
                script {
                    def fullImageName = "${env.REGISTRY}/${env.IMAGE_NAME}:${env.TAG}"
                    
                    // Update deployment using Python Kubernetes API
                    sh """
                        python3 << 'PYEOF'
import time
from kubernetes import client, config

# Load in-cluster config
config.load_incluster_config()

# Create API client
apps_v1 = client.AppsV1Api()
v1 = client.CoreV1Api()

print("Updating deployment with new image: ${fullImageName}")

try:
    # Read current deployment
    deployment = apps_v1.read_namespaced_deployment(name="flask-app", namespace="flask-app")
    
    # Update the image
    deployment.spec.template.spec.containers[0].image = "${fullImageName}"
    
    # Apply the update
    apps_v1.patch_namespaced_deployment(
        name="flask-app", 
        namespace="flask-app", 
        body=deployment
    )
    
    print("Deployment updated, waiting for rollout to complete...")
    
    # Wait for rollout to complete
    for i in range(18):  # 3 minute timeout (reduced from 5 minutes)
        try:
            deployment = apps_v1.read_namespaced_deployment(name="flask-app", namespace="flask-app")
            
            ready_replicas = deployment.status.ready_replicas or 0
            updated_replicas = deployment.status.updated_replicas or 0
            desired_replicas = deployment.spec.replicas
            
            print(f"Rollout status: {ready_replicas}/{desired_replicas} ready, {updated_replicas} updated")
            
            if (ready_replicas == desired_replicas and updated_replicas == desired_replicas):
                print("‚úÖ Deployment rollout completed successfully")
                
                # Show pod status
                pods = v1.list_namespaced_pod(namespace="flask-app", label_selector="app=flask-app")
                print("Pod status:")
                for pod in pods.items:
                    print(f"  {pod.metadata.name}: {pod.status.phase}")
                
                print(f"Deployment updated successfully with image: ${fullImageName}")
                exit(0)
                
            time.sleep(10)
            
        except Exception as e:
            print(f"Error checking deployment status: {e}")
            time.sleep(5)  # Shorter sleep on error
    
    print("‚ùå Deployment rollout timed out")
    exit(1)
    
except Exception as e:
    print(f"Failed to update deployment: {e}")
    exit(1)

PYEOF
                    """
                }
            }
        }

        stage('Generate Security Report') {
            steps {
                script {
                    // Generate a comprehensive security report
                    sh '''
                        mkdir -p security/reports
                        
                        # Create HTML security dashboard
                        cat > security/reports/security-dashboard.html << 'EOL'
<!DOCTYPE html>
<html>
<head>
    <title>DevSecOps Security Dashboard - Build ${BUILD_NUMBER}</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .header { background-color: #f4f4f4; padding: 20px; border-radius: 5px; }
        .section { margin: 20px 0; padding: 15px; border: 1px solid #ddd; border-radius: 5px; }
        .success { background-color: #d4edda; border-color: #c3e6cb; }
        .warning { background-color: #fff3cd; border-color: #ffeaa7; }
        .error { background-color: #f8d7da; border-color: #f5c6cb; }
        pre { background-color: #f8f9fa; padding: 10px; border-radius: 3px; overflow-x: auto; }
        .timestamp { color: #666; font-size: 0.9em; }
    </style>
</head>
<body>
    <div class="header">
        <h1>DevSecOps Security Dashboard</h1>
        <p>Build #${BUILD_NUMBER} - Generated on $(date)</p>
        <p>Jenkins Job: ${JOB_NAME}</p>
        <p>Git Commit: ${GIT_COMMIT}</p>
    </div>
    
    <div class="section success">
        <h2>‚úÖ Pipeline Status</h2>
        <p>Build completed successfully with security scans</p>
        <p>Image: ${REGISTRY}/${IMAGE_NAME}:${TAG}</p>
    </div>
    
    <div class="section">
        <h2>üìä Security Scan Results</h2>
        <p>Filesystem and container image scanned for vulnerabilities</p>
        <ul>
            <li>Trivy Filesystem Scan: Available in build artifacts</li>
            <li>Trivy Image Scan: Available in build artifacts</li>
            <li>SonarQube Analysis: Check SonarQube dashboard</li>
        </ul>
    </div>
    
    <div class="section">
        <h2>üîó Links</h2>
        <ul>
            <li><a href="${BUILD_URL}">Jenkins Build</a></li>
            <li><a href="${SONAR_HOST_URL}/dashboard?id=${SONAR_PROJECT_KEY}">SonarQube Project</a></li>
            <li><a href="http://grafana.local">Grafana Dashboard</a></li>
        </ul>
    </div>
    
    <div class="timestamp">
        Report generated at $(date)
    </div>
</body>
</html>
EOL
                        
                        echo "Security dashboard generated"
                    '''
                    
                    archiveArtifacts artifacts: 'security/reports/security-dashboard.html', allowEmptyArchive: true
                }
            }
        }
    }

    post {
        always {
            echo 'Pipeline execution completed'
            
            // Clean up any temporary files
            sh 'rm -f kaniko-job.yaml || true'
        }
        
        success {
            echo '‚úÖ Pipeline completed successfully!'
        }
        
        failure {
            echo '‚ùå Pipeline failed. Check the logs for details.'
        }
        
        unstable {
            echo '‚ö†Ô∏è Pipeline completed with warnings.'
        }
    }
}
